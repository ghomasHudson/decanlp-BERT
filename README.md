# decaNLP - BERT

Idea is to combine ideas from BERT (transformer architecture, pretrained language model) along with ideas from decaNLP (framing multitask learning as QA, pointer mechanism).
